{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d6324c-a851-484b-a046-61f9c26399b5",
   "metadata": {},
   "source": [
    "In this notebook, I demonstrate a reasoning model (deepseek-r1) training pipeline for a math reasoning task. I use GRPOTrainer from trl (huggingface) and unsltorh for fast inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f44c26c-f5e4-4014-b381-09ade62b7c4b",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d33d115-02e7-4135-b012-44f22e5f4ef5",
   "metadata": {},
   "source": [
    "We will be relying on Unsloth, vLLM and Transformers Reinforcement Learning (TRL) as the core packages for training and inferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3daec5-8339-4de8-b828-0f771170c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unsloth vllm\n",
    "!pip install --upgrade pillow\n",
    "# If you are running this notebook locally (not colab), you need to install `diffusers` too\n",
    "# !pip install diffusers\n",
    "\n",
    "# Temporarily install a specific TRL nightly version that supports GRPO\n",
    "!pip install git+https://github.com/huggingface/trl.git@e95f9fb74a3c3647b86f251b7e230ec51c64b72b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "616b13e7-fdfd-4be8-abdd-ecc1327fb439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 03-24 11:41:05 __init__.py:207] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, PatchFastRL\n",
    "\n",
    "# Execute the Patch\n",
    "PatchFastRL(\"GRPO\", FastLanguageModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ca70c3",
   "metadata": {
    "papermill": {
     "duration": 29.931605,
     "end_time": "2025-02-03T14:01:28.844610",
     "exception": false,
     "start_time": "2025-02-03T14:00:58.913005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import copy\n",
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset as TorchDataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AdamW,\n",
    "    BitsAndBytesConfig,\n",
    "    PrinterCallback\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from Levenshtein import ratio as levenshtein_ratio\n",
    "from tqdm import tqdm\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d821331a",
   "metadata": {
    "papermill": {
     "duration": 0.012901,
     "end_time": "2025-02-03T14:01:28.865800",
     "exception": false,
     "start_time": "2025-02-03T14:01:28.852899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    MAX_TRAIN = 100\n",
    "    MAX_TOKENS = 2048\n",
    "    NUM_GENERATIONS = 4\n",
    "    USE_PEFT = True\n",
    "    BATCH_SIZE=1\n",
    "    MAX_STEPS = 80\n",
    "    \n",
    "    BETA = 0.04\n",
    "    LR = 1.e-5\n",
    "    \n",
    "    model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "    splitter = '<ï½œAssistantï½œ>'\n",
    "    \n",
    "    step_count=10\n",
    "    DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9371b817-9a1a-4855-969e-405513c3954e",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "295cd55c-da67-4ae4-b464-281dc47be71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/dortp58/.cache/kagglehub/datasets/artemgoncarov/math-problems-imo/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"artemgoncarov/math-problems-imo\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d14b0fa2",
   "metadata": {
    "papermill": {
     "duration": 0.012393,
     "end_time": "2025-02-03T14:01:28.885970",
     "exception": false,
     "start_time": "2025-02-03T14:01:28.873577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_boxed_text(text):\n",
    "    pattern = r'oxed{(.*?)}'\n",
    "    matches = re.findall(pattern, text)\n",
    "    if not matches:\n",
    "        return \"\"\n",
    "    for match in matches[::-1]:\n",
    "        if match != \"\":\n",
    "            return match\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdaeb253",
   "metadata": {
    "papermill": {
     "duration": 1.956537,
     "end_time": "2025-02-03T14:01:30.850192",
     "exception": false,
     "start_time": "2025-02-03T14:01:28.893655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(path)\n",
    "df = df.reset_index().rename({'index': 'id'}, axis=1)\n",
    "df['answer'] = df['solution'].map(extract_boxed_text)\n",
    "\n",
    "def is_valid_answer(s):\n",
    "    try:\n",
    "        if float(s) == int(s):\n",
    "            i = int(s)\n",
    "            return 0<=i<1000\n",
    "        else:\n",
    "            return False\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "mask = df['answer'].map(is_valid_answer)\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49382b44",
   "metadata": {
    "papermill": {
     "duration": 0.012534,
     "end_time": "2025-02-03T14:01:30.871068",
     "exception": false,
     "start_time": "2025-02-03T14:01:30.858534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'problem', 'solution', 'answer', '__index_level_0__'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "df = df.iloc[:CFG.MAX_TRAIN]\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1556d0e",
   "metadata": {
    "papermill": {
     "duration": 0.022581,
     "end_time": "2025-02-03T14:01:30.934331",
     "exception": false,
     "start_time": "2025-02-03T14:01:30.911750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'problem', 'solution', 'answer', '__index_level_0__'],\n",
       "        num_rows: 90\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'problem', 'solution', 'answer', '__index_level_0__'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f846cc-3d63-4dc4-8d20-2b950ff61b85",
   "metadata": {},
   "source": [
    "# Training setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7803d50d-1b21-4ab1-aead-a6075d5f0b02",
   "metadata": {},
   "source": [
    "I used 3 different reward functions, and used a prompt from the Deepseek paper (https://arxiv.org/abs/2501.12948)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f93269a",
   "metadata": {
    "papermill": {
     "duration": 0.01662,
     "end_time": "2025-02-03T14:01:31.004868",
     "exception": false,
     "start_time": "2025-02-03T14:01:30.988248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## We would also want a reward function based on accuracy\n",
    "# split after </think>, then get the answer within bbox\n",
    "\n",
    "## We can also do a reward based on Similarity of \n",
    "\n",
    "import re\n",
    "\n",
    "def format_reward_func(completions, **kwargs):\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"^<think>.*?</think>.*?oxed{(.*?)}.*?$\"\n",
    "    matches = [re.match(pattern, content, re.DOTALL) for content in completions]\n",
    "    return [1.0 if match else 0.0 for match in matches]\n",
    "\n",
    "\n",
    "def extract_boxed_text(text):\n",
    "    pattern = r'oxed{(.*?)}'\n",
    "    matches = re.findall(pattern, text)\n",
    "    if not matches:\n",
    "        return \"\"\n",
    "    for match in matches[::-1]:\n",
    "        if match != \"\":\n",
    "            return match\n",
    "    return \"\"\n",
    "\n",
    "def accuracy_reward_func(completions, answer, **kwargs):\n",
    "    # Regular expression to capture content inside \\boxed{}\n",
    "    contents = [extract_boxed_text(completion) for completion in completions]\n",
    "    # Reward 1 if the content is the same as the ground truth, 0 otherwise\n",
    "    return [1.0 if c == str(gt) else 0.0 for c, gt in zip(contents, answer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4489efbf",
   "metadata": {
    "papermill": {
     "duration": 0.014252,
     "end_time": "2025-02-03T14:01:31.027035",
     "exception": false,
     "start_time": "2025-02-03T14:01:31.012783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def levenshtein_reward_func(completions, solution, **kwargs):\n",
    "    res = []\n",
    "    for completion, sol in zip(completions, solution):\n",
    "        if '</think>' in completion:\n",
    "            t = completion.split('</think>')[-1]\n",
    "            res.append(levenshtein_ratio(t, sol))\n",
    "        else:\n",
    "            res.append(0.0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd2ce37",
   "metadata": {
    "papermill": {
     "duration": 9.441766,
     "end_time": "2025-02-03T14:01:40.476719",
     "exception": false,
     "start_time": "2025-02-03T14:01:31.034953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Switching from Unsloth dynamic quant to normal quant since\n",
      "we do not yet support fast inference for unsloth/deepseek-r1-distill-qwen-1.5b-unsloth-bnb-4bit\n",
      "==((====))==  Unsloth 2025.3.17: Fast Qwen2 patching. Transformers: 4.49.0. vLLM: 0.7.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3060 Laptop GPU. Num GPUs = 1. Max memory: 5.792 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: vLLM loading unsloth/deepseek-r1-distill-qwen-1.5b-bnb-4bit with actual GPU utilization = 63.12%\n",
      "Unsloth: Your GPU has CUDA compute capability 8.6 with VRAM = 5.79 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 2048. Num Sequences = 128.\n",
      "Unsloth: vLLM's KV Cache can use up to 1.89 GB. Also swap space = 1 GB.\n",
      "INFO 03-24 11:42:50 config.py:549] This model supports multiple tasks: {'classify', 'embed', 'generate', 'reward', 'score'}. Defaulting to 'generate'.\n",
      "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection'], 'llm_int8_threshold': 6.0}\n",
      "INFO 03-24 11:42:50 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='unsloth/deepseek-r1-distill-qwen-1.5b-bnb-4bit', speculative_config=None, tokenizer='unsloth/deepseek-r1-distill-qwen-1.5b-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/deepseek-r1-distill-qwen-1.5b-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":128}, use_cached_outputs=False, \n",
      "INFO 03-24 11:42:51 cuda.py:229] Using Flash Attention backend.\n",
      "INFO 03-24 11:42:51 model_runner.py:1110] Starting to load model unsloth/deepseek-r1-distill-qwen-1.5b-bnb-4bit...\n",
      "INFO 03-24 11:42:51 loader.py:1089] Loading weights with BitsAndBytes quantization.  May take a while ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W324 11:42:51.971983782 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-24 11:42:53 weight_utils.py:254] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bb87c0234e4f8ca6d6b29381a6383a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edb080a7aa346218d7ed1e26f1a93fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-24 11:42:54 model_runner.py:1115] Loading model weights took 1.5365 GB\n",
      "INFO 03-24 11:42:54 punica_selector.py:18] Using PunicaWrapperGPU.\n",
      "INFO 03-24 11:42:55 worker.py:267] Memory profiling takes 1.08 seconds\n",
      "INFO 03-24 11:42:55 worker.py:267] the current vLLM instance can use total_gpu_memory (5.79GiB) x gpu_memory_utilization (0.63) = 3.66GiB\n",
      "INFO 03-24 11:42:55 worker.py:267] model weights take 1.54GiB; non_torch_memory takes 0.03GiB; PyTorch activation peak memory takes 0.70GiB; the rest of the memory reserved for KV Cache is 1.38GiB.\n",
      "INFO 03-24 11:42:55 executor_base.py:111] # cuda blocks: 3240, # CPU blocks: 2340\n",
      "INFO 03-24 11:42:55 executor_base.py:116] Maximum concurrency for 2048 tokens per request: 25.31x\n",
      "INFO 03-24 11:42:56 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:09<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-24 11:43:05 model_runner.py:1562] Graph capturing finished in 9 secs, took 0.36 GiB\n",
      "INFO 03-24 11:43:05 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 11.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Unsloth 2025.3.17 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# Load Base Model & Tokenizer\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = CFG.model_name,\n",
    "    max_seq_length = CFG.MAX_TOKENS,                      # Can increase for longer reasoning traces\n",
    "    load_in_4bit = True,                        # False for LoRA 16bit\n",
    "    fast_inference = True,                      # Enable vLLM fast inference\n",
    "    max_lora_rank = 64,                         # Larger rank = smarter, but slower\n",
    "    gpu_memory_utilization = 0.7,               # Reduce if out of memory\n",
    ")\n",
    "\n",
    "# Prepare Model for Parameter Efficient Fine Tuning\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,                                     # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = 32,                            # LoRA Rank\n",
    "    use_gradient_checkpointing = \"unsloth\",     # Enable long context finetuning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70d42d36",
   "metadata": {
    "papermill": {
     "duration": 0.547352,
     "end_time": "2025-02-03T14:01:41.033006",
     "exception": false,
     "start_time": "2025-02-03T14:01:40.485654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_prompt(sample):\n",
    "    question = sample['problem']\n",
    "    chat = [{\"role\": \"system\", \"content\": \"A conversation between User and Assistant. The user asks a question, and the Assistant solves it.  The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>\"},\n",
    "            {\"role\": \"user\", \"content\": question + ' Return final answer within \\\\boxed{}, after taking modulo 1000.'},]\n",
    "    sample['prompt'] = tokenizer.apply_chat_template(\n",
    "            conversation=chat,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bdfccf3",
   "metadata": {
    "papermill": {
     "duration": 0.28644,
     "end_time": "2025-02-03T14:01:41.327966",
     "exception": false,
     "start_time": "2025-02-03T14:01:41.041526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29846fd2c46447a97d24003c7b0e9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615526d3831e44c0986a6bd878af1634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(create_prompt)#, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd0824bb",
   "metadata": {
    "papermill": {
     "duration": 0.014219,
     "end_time": "2025-02-03T14:01:41.350823",
     "exception": false,
     "start_time": "2025-02-03T14:01:41.336604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen(model, text, max_tokens):\n",
    "    model_input = tokenizer(text, return_tensors='pt').to(model.device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tok = model.generate(**model_input, max_new_tokens=max_tokens, pad_token_id=tokenizer.pad_token_type_id)\n",
    "        outputs = []\n",
    "        for i in range(len(tok)):\n",
    "            res = tokenizer.decode(tok[i], skip_special_tokens=True)\n",
    "            output = res.split(CFG.splitter)[-1]\n",
    "            outputs.append(output)\n",
    "        return outputs[0] if len(outputs) == 1 else outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d85db3c8",
   "metadata": {
    "papermill": {
     "duration": 0.015335,
     "end_time": "2025-02-03T14:01:41.374231",
     "exception": false,
     "start_time": "2025-02-03T14:01:41.358896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_rewards(model, dataset, reward_functions: dict[str, callable], max_tokens: int, num_generations: int):\n",
    "    completions = []\n",
    "    other_info = []\n",
    "    for example in tqdm(dataset):\n",
    "        txt = example['prompt']\n",
    "        kw = {k: v for k, v in example.items() if k not in {'prompt', 'completion'}}\n",
    "        for _ in range(num_generations):\n",
    "            other_info.append(kw)\n",
    "            \n",
    "        completion = gen(model, [txt]*num_generations, max_tokens)\n",
    "        if isinstance(completion, str):\n",
    "            completions.append(completion)\n",
    "        else:\n",
    "            completions += completion\n",
    "        \n",
    "    kwargs = {k: [d[k] for d in other_info] for k in other_info[0].keys()}\n",
    "    res = {}\n",
    "    for nm, reward_func in reward_functions.items():\n",
    "        v = reward_func(completions=completions, **kwargs)\n",
    "        print(nm, np.mean(v))\n",
    "        res[nm] = np.mean(v)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7e7a438",
   "metadata": {
    "papermill": {
     "duration": 0.012393,
     "end_time": "2025-02-03T14:01:41.394714",
     "exception": false,
     "start_time": "2025-02-03T14:01:41.382321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reward_functions = {'formatting': format_reward_func, 'accuracy': accuracy_reward_func, 'solution_quality': levenshtein_reward_func}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "472bb642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:01:41.411377Z",
     "iopub.status.busy": "2025-02-03T14:01:41.411164Z",
     "iopub.status.idle": "2025-02-03T14:18:10.467045Z",
     "shell.execute_reply": "2025-02-03T14:18:10.466319Z"
    },
    "papermill": {
     "duration": 989.070042,
     "end_time": "2025-02-03T14:18:10.472782",
     "exception": false,
     "start_time": "2025-02-03T14:01:41.402740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [16:29<00:00, 98.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formatting 0.725\n",
      "accuracy 0.6\n",
      "solution_quality 0.3062495202351799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not CFG.DEBUG:\n",
    "    original_rewards = evaluate_rewards(model=original_model, dataset=dataset['test'], reward_functions=reward_functions, max_tokens=CFG.MAX_TOKENS, num_generations=CFG.NUM_GENERATIONS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffe548-cd3d-4ee9-88f1-34d1f0a07c32",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c74edfb7",
   "metadata": {
    "papermill": {
     "duration": 0.051485,
     "end_time": "2025-02-03T14:18:10.533351",
     "exception": false,
     "start_time": "2025-02-03T14:18:10.481866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 4\n"
     ]
    }
   ],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "dtstr = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "output_directory=f\"./DEEPSEEK-GRPO-{dtstr}\"\n",
    "\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=output_directory,\n",
    "    use_vllm = True,\n",
    "    learning_rate=CFG.LR,\n",
    "    adam_beta1 = 0.9,                           # AdamW optimizer momentum parameter\n",
    "    adam_beta2 = 0.99,                          # AdamW optimizer second moment parameter\n",
    "    weight_decay = 0.1,                         # L2 regularization to prevent overfitting\n",
    "    warmup_ratio = 0.1,                         # Portion of training steps for learning rate warmup\n",
    "    lr_scheduler_type = \"cosine\",               # Learning rate decay schedule type\n",
    "    optim = \"adamw_8bit\",\n",
    "    per_device_train_batch_size=CFG.BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    max_steps=CFG.MAX_STEPS,\n",
    "    \n",
    "    max_completion_length=CFG.MAX_TOKENS,  #2048\n",
    "    num_generations=CFG.NUM_GENERATIONS,\n",
    "    \n",
    "    logging_steps=CFG.step_count,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=CFG.step_count,\n",
    "#     eval_strategy=\"steps\",\n",
    "#     eval_steps=CFG.step_count,\n",
    "#     do_eval=True,\n",
    "    # gradient_checkpointing=True,  # Will crash the whole thing\n",
    "    report_to=\"none\",\n",
    "    overwrite_output_dir = 'True',    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0577e1aa",
   "metadata": {
    "papermill": {
     "duration": 0.662342,
     "end_time": "2025-02-03T14:18:11.205107",
     "exception": false,
     "start_time": "2025-02-03T14:18:10.542765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = GRPOTrainer(\n",
    "        model=model,\n",
    "        reward_funcs=list(reward_functions.values()),\n",
    "        args=training_args,\n",
    "        train_dataset=dataset['train'],\n",
    "        callbacks=[PrinterCallback()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "415a44e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:18:11.224383Z",
     "iopub.status.busy": "2025-02-03T14:18:11.224149Z",
     "iopub.status.idle": "2025-02-03T17:58:21.765905Z",
     "shell.execute_reply": "2025-02-03T17:58:21.765226Z"
    },
    "papermill": {
     "duration": 13210.55223,
     "end_time": "2025-02-03T17:58:21.767089",
     "exception": false,
     "start_time": "2025-02-03T14:18:11.214859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 3:36:46, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': -0.0, 'grad_norm': 0.034604042768478394, 'learning_rate': 8.750000000000001e-06, 'completion_length': 1693.35, 'rewards/format_reward_func': 0.325, 'rewards/accuracy_reward_func': 0.35, 'rewards/levenshtein_reward_func': 0.1815756194293499, 'reward': 0.8565756164491176, 'reward_std': 0.3982465725392103, 'kl': -5.865097045898438e-06, 'epoch': 0.1111111111111111}\n",
      "{'loss': -0.0, 'grad_norm': 0.0, 'learning_rate': 7.500000000000001e-06, 'completion_length': 1424.0, 'rewards/format_reward_func': 0.425, 'rewards/accuracy_reward_func': 0.35, 'rewards/levenshtein_reward_func': 0.18992570266127587, 'reward': 0.9649257034063339, 'reward_std': 0.35146077554672955, 'kl': -6.186962127685547e-06, 'epoch': 0.2222222222222222}\n",
      "{'loss': -0.0, 'grad_norm': 0.026678849011659622, 'learning_rate': 6.25e-06, 'completion_length': 1210.225, 'rewards/format_reward_func': 0.675, 'rewards/accuracy_reward_func': 0.425, 'rewards/levenshtein_reward_func': 0.30511854588985443, 'reward': 1.4051185488700866, 'reward_std': 0.4244503375142813, 'kl': -6.318092346191406e-06, 'epoch': 0.3333333333333333}\n",
      "{'loss': 0.0, 'grad_norm': 0.026079410687088966, 'learning_rate': 5e-06, 'completion_length': 1563.325, 'rewards/format_reward_func': 0.375, 'rewards/accuracy_reward_func': 0.325, 'rewards/levenshtein_reward_func': 0.21794616840779782, 'reward': 0.9179461866617202, 'reward_std': 0.5498886249959469, 'kl': -6.777048110961914e-06, 'epoch': 0.4444444444444444}\n",
      "{'loss': -0.0, 'grad_norm': 0.04918307065963745, 'learning_rate': 3.7500000000000005e-06, 'completion_length': 1136.775, 'rewards/format_reward_func': 0.675, 'rewards/accuracy_reward_func': 0.5, 'rewards/levenshtein_reward_func': 0.3341621644794941, 'reward': 1.5091621674597264, 'reward_std': 0.6207844451069832, 'kl': -5.3584575653076175e-06, 'epoch': 0.5555555555555556}\n",
      "{'loss': -0.0, 'grad_norm': 0.0, 'learning_rate': 2.5e-06, 'completion_length': 1360.675, 'rewards/format_reward_func': 0.6, 'rewards/accuracy_reward_func': 0.55, 'rewards/levenshtein_reward_func': 0.28910536170005796, 'reward': 1.4391054034233093, 'reward_std': 0.46107444204390047, 'kl': -6.300210952758789e-06, 'epoch': 0.6666666666666666}\n",
      "{'loss': -0.0, 'grad_norm': 0.025699466466903687, 'learning_rate': 1.25e-06, 'completion_length': 1426.45, 'rewards/format_reward_func': 0.6, 'rewards/accuracy_reward_func': 0.575, 'rewards/levenshtein_reward_func': 0.27479969561100004, 'reward': 1.449799683690071, 'reward_std': 0.8232996046543122, 'kl': -5.9247016906738285e-06, 'epoch': 0.7777777777777778}\n",
      "{'loss': -0.0, 'grad_norm': 0.03497441112995148, 'learning_rate': 0.0, 'completion_length': 1361.7, 'rewards/format_reward_func': 0.625, 'rewards/accuracy_reward_func': 0.525, 'rewards/levenshtein_reward_func': 0.2715685561299324, 'reward': 1.4215685188770295, 'reward_std': 0.668209108710289, 'kl': -6.109476089477539e-06, 'epoch': 0.8888888888888888}\n",
      "{'train_runtime': 13210.1595, 'train_samples_per_second': 0.006, 'train_steps_per_second': 0.006, 'train_loss': -2.279258296766784e-07, 'epoch': 0.8888888888888888}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=-2.279258296766784e-07, metrics={'train_runtime': 13210.1595, 'train_samples_per_second': 0.006, 'train_steps_per_second': 0.006, 'total_flos': 0.0, 'train_loss': -2.279258296766784e-07})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf26fc-2257-41a0-b053-d443c1979f00",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b602ff35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T17:58:21.787476Z",
     "iopub.status.busy": "2025-02-03T17:58:21.787246Z",
     "iopub.status.idle": "2025-02-03T17:58:22.042798Z",
     "shell.execute_reply": "2025-02-03T17:58:22.042093Z"
    },
    "papermill": {
     "duration": 0.267148,
     "end_time": "2025-02-03T17:58:22.044105",
     "exception": false,
     "start_time": "2025-02-03T17:58:21.776957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model\n"
     ]
    }
   ],
   "source": [
    "if CFG.USE_PEFT:\n",
    "    print('Loading trained model')\n",
    "    CHKPT = CFG.MAX_STEPS\n",
    "    adapter_model_name = f'{output_directory}/checkpoint-{CHKPT}/'\n",
    "    new_model = PeftModel.from_pretrained(original_model, adapter_model_name)\n",
    "else:\n",
    "    new_model = original_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4edae8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T17:58:22.064309Z",
     "iopub.status.busy": "2025-02-03T17:58:22.064075Z",
     "iopub.status.idle": "2025-02-03T18:21:10.760745Z",
     "shell.execute_reply": "2025-02-03T18:21:10.760031Z"
    },
    "papermill": {
     "duration": 1368.711676,
     "end_time": "2025-02-03T18:21:10.765701",
     "exception": false,
     "start_time": "2025-02-03T17:58:22.054025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [22:48<00:00, 136.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formatting 0.675\n",
      "accuracy 0.525\n",
      "solution_quality 0.27533443147722725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'formatting': 0.675,\n",
       " 'accuracy': 0.525,\n",
       " 'solution_quality': 0.27533443147722725}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = evaluate_rewards(model=new_model, dataset=dataset['test'], reward_functions=reward_functions, max_tokens=CFG.MAX_TOKENS, num_generations=CFG.NUM_GENERATIONS)\n",
    "rewards"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaL4",
   "dataSources": [
    {
     "databundleVersionId": 9869096,
     "sourceId": 86023,
     "sourceType": "competition"
    },
    {
     "datasetId": 6485000,
     "sourceId": 10473687,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 220111282,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 225262,
     "modelInstanceId": 204042,
     "sourceId": 238909,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15637.8583,
   "end_time": "2025-02-03T18:21:14.291159",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-03T14:00:36.432859",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "085eb857490a42f39e59acc73559edb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "09438903e3f5445a8909080f2d89c496": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_085eb857490a42f39e59acc73559edb9",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_f7a60235b3034569b3e46b14996cf547",
       "tabbable": null,
       "tooltip": null,
       "value": "Map:â€‡100%"
      }
     },
     "131ee81312ad4544bd223f98a00d1e98": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15c0fc47b92a4179957caa84bb99721a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a71b8199c544e02a6d0951c2d7bf521": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7037125fd7574edb81f16e7cf5168a22",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_9708774e778c4416845fbdfb95e52779",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡10/10â€‡[00:00&lt;00:00,â€‡614.69â€‡examples/s]"
      }
     },
     "1f07e9122c534a6e8ffb493dd50846f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_15c0fc47b92a4179957caa84bb99721a",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_8d507a0c9f02466e89ffefbc37b5ad67",
       "tabbable": null,
       "tooltip": null,
       "value": "Map:â€‡100%"
      }
     },
     "31e7d89fcebf42a9a16ddee7f2c8b2b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4f7952c306894c5396d159636b0cadc9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6215268ab6b94e1690a5b3f38a021947",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_95ae440a888a4ca08089711b65db72bc",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡90/90â€‡[00:00&lt;00:00,â€‡1620.74â€‡examples/s]"
      }
     },
     "6215268ab6b94e1690a5b3f38a021947": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63a42b61828d4303a07556ac77fe188a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7037125fd7574edb81f16e7cf5168a22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "85dedf4d1e10457a9466ce337cab8869": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1f07e9122c534a6e8ffb493dd50846f1",
        "IPY_MODEL_dd608ecf364746e98877864d69b035b1",
        "IPY_MODEL_1a71b8199c544e02a6d0951c2d7bf521"
       ],
       "layout": "IPY_MODEL_b5065cc44305474bb0b6f477a86c45b3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8d507a0c9f02466e89ffefbc37b5ad67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "95ae440a888a4ca08089711b65db72bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9708774e778c4416845fbdfb95e52779": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "af7528d5d5b44a859668af5a753de91b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_131ee81312ad4544bd223f98a00d1e98",
       "max": 90,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bfb2d102c53746fa9412afab5f819b73",
       "tabbable": null,
       "tooltip": null,
       "value": 90
      }
     },
     "b5065cc44305474bb0b6f477a86c45b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bfb2d102c53746fa9412afab5f819b73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dd608ecf364746e98877864d69b035b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_31e7d89fcebf42a9a16ddee7f2c8b2b1",
       "max": 10,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_63a42b61828d4303a07556ac77fe188a",
       "tabbable": null,
       "tooltip": null,
       "value": 10
      }
     },
     "e74698aecba2467797c3be9666e2af9e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e7bfa1465d3f4a81bce0ad5a5fe8fb9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_09438903e3f5445a8909080f2d89c496",
        "IPY_MODEL_af7528d5d5b44a859668af5a753de91b",
        "IPY_MODEL_4f7952c306894c5396d159636b0cadc9"
       ],
       "layout": "IPY_MODEL_e74698aecba2467797c3be9666e2af9e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f7a60235b3034569b3e46b14996cf547": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
